name: Scraper Health Check

on:
  schedule:
    # Run daily at 6am UTC
    - cron: '0 6 * * *'
  workflow_dispatch:
    inputs:
      retailers:
        description: 'Comma-separated list of retailers to test (leave empty for all)'
        required: false
        default: ''

jobs:
  health-check:
    name: Test Scraper Endpoints
    runs-on: ubuntu-latest
    timeout-minutes: 15
    permissions:
      contents: read
      issues: write

    steps:
      - uses: actions/checkout@v6

      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: '3.10'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run health checks
        id: health
        env:
          SELECTED_RETAILERS: ${{ github.event.inputs.retailers }}
        run: |
          python -c "
          import os
          import requests
          import yaml
          import sys

          with open('config/retailers.yaml', 'r') as f:
              config = yaml.safe_load(f)

          retailers = config.get('retailers', {})
          failures = []

          # Filter by selected retailers if specified
          selected = {r.strip() for r in os.getenv('SELECTED_RETAILERS', '').split(',') if r.strip()}
          if selected:
              print(f'Testing selected retailers: {sorted(selected)}')

          # Use browser-like headers to avoid bot detection on health checks
          headers = {
              'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
              'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
          }

          for name, cfg in retailers.items():
              if selected and name not in selected:
                  continue
              if not cfg.get('enabled', True):
                  continue

              # Use health_check_url if available (for bot-protected sites)
              # Otherwise fall back to base_url
              health_url = cfg.get('health_check_url') or cfg.get('base_url', '')
              if not health_url:
                  continue

              print(f'Testing {name}: {health_url}')
              try:
                  resp = requests.get(health_url, timeout=15, allow_redirects=True, headers=headers)
                  if resp.status_code >= 400:
                      failures.append(f'{name}: HTTP {resp.status_code}')
                      print(f'  ‚ùå HTTP {resp.status_code}')
                  else:
                      print(f'  ‚úÖ HTTP {resp.status_code}')
              except Exception as e:
                  failures.append(f'{name}: {str(e)[:50]}')
                  print(f'  ‚ùå Error: {e}')

          if failures:
              print(f'\n‚ö†Ô∏è {len(failures)} endpoint(s) failed:')
              for f in failures:
                  print(f'  - {f}')
              sys.exit(1)
          else:
              print('\n‚úÖ All endpoints healthy')
          "

      - name: Create issue on failure
        if: failure()
        uses: actions/github-script@v8
        with:
          script: |
            const title = `üö® Scraper Health Check Failed - ${new Date().toISOString().split('T')[0]}`;

            // Check for existing open issue
            const issues = await github.rest.issues.listForRepo({
              owner: context.repo.owner,
              repo: context.repo.repo,
              state: 'open',
              labels: 'scraper-health'
            });

            if (issues.data.length === 0) {
              await github.rest.issues.create({
                owner: context.repo.owner,
                repo: context.repo.repo,
                title: title,
                body: `The daily scraper health check has failed.\n\nSee the [workflow run](${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}) for details.`,
                labels: ['bug', 'scraper-health']
              });
            }
