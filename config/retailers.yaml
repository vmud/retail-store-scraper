# Multi-Retailer Store Scraper Configuration
# This file contains configuration for all supported retailers

# =============================================================================
# CLOUD STORAGE CONFIGURATION (GCS Integration)
# =============================================================================
# Sync scraped data to Google Cloud Storage for backup and team access.
# Credentials are loaded from environment variables (see .env.example).
#
# GCS bucket structure:
#   gs://{bucket}/
#   ├── {retailer}/stores_latest.{json,csv,xlsx}  (overwritten, versioned)
#   └── history/{retailer}/stores_YYYY-MM-DD_HHMMSS.{ext}  (optional)

cloud_storage:
  enabled: false          # Set to true or use --cloud CLI flag
  provider: "gcs"         # Currently only GCS supported
  max_retries: 3          # Retry attempts for transient errors
  retry_delay: 2.0        # Base delay (exponential backoff: 2s, 4s, 8s)
  enable_history: false   # Upload timestamped copies to history/ folder

# =============================================================================
# PROXY CONFIGURATION (Oxylabs Integration)
# =============================================================================
# Credentials are loaded from environment variables:
#   OXYLABS_USERNAME - Your Oxylabs username
#   OXYLABS_PASSWORD - Your Oxylabs password
#
# Modes:
#   direct          - No proxy (default, use built-in delays)
#   residential     - Oxylabs Residential Proxies (175M+ IPs)
#   web_scraper_api - Oxylabs Web Scraper API (managed service)
# =============================================================================

proxy:
  # Global proxy settings (can be overridden per retailer)
  mode: "direct"  # Options: direct, residential, web_scraper_api

  # Residential proxy settings
  residential:
    endpoint: "pr.oxylabs.io:7777"
    country_code: "us"
    session_type: "rotating"  # rotating or sticky

  # Web Scraper API settings
  web_scraper_api:
    endpoint: "https://realtime.oxylabs.io/v1/queries"
    render_js: false    # Enable for JS-heavy sites (Walmart, etc.)
    parse: false        # Return parsed JSON instead of HTML

  # Request settings when using proxies
  timeout: 60
  max_retries: 3
  retry_delay: 2.0

# =============================================================================
# DEFAULT SETTINGS
# =============================================================================
# Can be overridden per retailer
# Dual delay profiles: optimized speeds when using proxies vs. direct mode

defaults:
  # Dual delay profiles: direct (conservative) vs proxied (aggressive)
  delays:
    direct:
      min_delay: 2.0
      max_delay: 5.0
    proxied:
      min_delay: 0.2
      max_delay: 0.5

  max_retries: 3
  timeout: 30
  rate_limit_base_wait: 30
  pause_50_requests: 50
  pause_50_min: 30
  pause_50_max: 60
  pause_200_requests: 200
  pause_200_min: 120
  pause_200_max: 180
  checkpoint_interval: 100

# Retailer-specific configurations
retailers:
  verizon:
    name: "Verizon"
    enabled: true
    base_url: "https://www.verizon.com"
    # Verizon uses 4-phase discovery (no sitemap)
    sitemap_urls: []
    discovery_method: "html_crawl"
    # Dual delay profiles for 9.6x speedup with proxies
    delays:
      direct:
        min_delay: 2.0
        max_delay: 5.0
      proxied:
        min_delay: 0.15
        max_delay: 0.35
    checkpoint_interval: 10
    # Parallel workers for discovery phases (Phases 2-3: cities and store URLs)
    # Higher values = faster discovery but more concurrent connections
    discovery_workers: 10
    # Parallel workers for store detail extraction (Phase 4)
    # Higher values = faster but more aggressive (use with residential proxy)
    parallel_workers: 7
    # Disable long pauses when using residential proxy
    pause_50_requests: 999999
    pause_200_requests: 999999
    pause_50_min: 0
    pause_50_max: 0
    pause_200_min: 0
    pause_200_max: 0
    # Proxy override: Verizon works well with residential proxies
    proxy:
      mode: "residential"
      render_js: false
    output_fields:
      - name
      - street_address
      - city
      - state
      - zip
      - country
      - latitude
      - longitude
      - phone
      - url
      - sub_channel
      - dealer_name
      - store_location
      - retailer_store_number
      - verizon_uid
      - scraped_at

  att:
    name: "AT&T"
    enabled: true
    base_url: "https://www.att.com"
    sitemap_urls:
      - "https://www.att.com/stores/sitemap_0.xml"
    discovery_method: "sitemap"
    # Dual delay profiles for speedup with proxies
    delays:
      direct:
        min_delay: 2.0
        max_delay: 5.0
      proxied:
        min_delay: 0.2
        max_delay: 0.4
    checkpoint_interval: 100
    # Parallel workers for store detail extraction
    # Higher values = faster but more aggressive (use with residential proxy)
    parallel_workers: 5
    # Disable long pauses when using residential proxy
    pause_50_requests: 999999
    pause_200_requests: 999999
    pause_50_min: 0
    pause_50_max: 0
    pause_200_min: 0
    pause_200_max: 0
    # Sitemap-based scraping with low anti-bot measures
    proxy:
      mode: "residential"
    output_fields:
      - store_id
      - name
      - telephone
      - street_address
      - city
      - state
      - postal_code
      - country
      - rating_value
      - rating_count
      - url
      - sub_channel
      - dealer_name
      - scraped_at

  target:
    name: "Target"
    enabled: true
    base_url: "https://www.target.com"
    sitemap_urls:
      - "https://www.target.com/store-locator/sitemap.xml.gz"
    discovery_method: "sitemap_gzip"
    api_url: "https://redsky.target.com/redsky_aggregations/v1/web/store_location_v1"
    # Dual delay profiles for 5x speedup with proxies
    delays:
      direct:
        min_delay: 0.5
        max_delay: 1.0
      proxied:
        min_delay: 0.1
        max_delay: 0.2
    checkpoint_interval: 100
    # Parallel workers for store detail extraction
    # Higher values = faster but more aggressive (use with residential proxy)
    parallel_workers: 5
    # Disable long pauses when using residential proxy
    pause_50_requests: 999999
    pause_200_requests: 999999
    pause_50_min: 0
    pause_50_max: 0
    pause_200_min: 0
    pause_200_max: 0
    # API-based scraping, residential proxy for reliability
    proxy:
      mode: "residential"
    output_fields:
      - store_id
      - name
      - status
      - format
      - street_address
      - city
      - state
      - zip
      - country
      - latitude
      - longitude
      - phone
      - capabilities
      - building_area
      - url
      - scraped_at

  tmobile:
    name: "T-Mobile"
    enabled: true
    base_url: "https://www.t-mobile.com"
    sitemap_urls:
      - "https://www.t-mobile.com/stores/sitemap1.xml"
      - "https://www.t-mobile.com/stores/sitemap2.xml"
    discovery_method: "sitemap_paginated"
    # Dual delay profiles for speedup with proxies
    delays:
      direct:
        min_delay: 0.5
        max_delay: 1.0
      proxied:
        min_delay: 0.2
        max_delay: 0.4
    checkpoint_interval: 100
    # Parallel workers for store detail extraction
    # Higher values = faster but more aggressive (use with residential proxy)
    parallel_workers: 5
    # Disable long pauses when using residential proxy
    pause_50_requests: 999999
    pause_200_requests: 999999
    pause_50_min: 0
    pause_50_max: 0
    pause_200_min: 0
    pause_200_max: 0
    # Sitemap-based scraping with Web Scraper API for Akamai bypass
    # Note: residential proxy blocked by T-Mobile's Akamai Bot Manager
    proxy:
      mode: "web_scraper_api"
      render_js: false
    output_fields:
      - store_id
      - branch_code
      - name
      - store_type
      - street_address
      - city
      - state
      - zip
      - country
      - latitude
      - longitude
      - phone
      - opening_hours
      - url
      - scraped_at

  walmart:
    name: "Walmart"
    enabled: true
    base_url: "https://www.walmart.com"
    sitemap_urls:
      - "https://www.walmart.com/sitemap_store_main_supercenter.xml.gz"
      - "https://www.walmart.com/sitemap_store_main_discount.xml.gz"
      - "https://www.walmart.com/sitemap_store_main_neighborhood.xml.gz"
      - "https://www.walmart.com/sitemap_store_main_other.xml.gz"
    discovery_method: "sitemap_gzip"
    # Dual delay profiles for speedup with proxies
    delays:
      direct:
        min_delay: 1.0
        max_delay: 2.0
      proxied:
        min_delay: 0.2
        max_delay: 0.5
    checkpoint_interval: 100
    # Disable long pauses when using residential proxy
    pause_50_requests: 999999
    pause_200_requests: 999999
    pause_50_min: 0
    pause_50_max: 0
    pause_200_min: 0
    pause_200_max: 0
    # HYBRID PROXY MODE (configured in walmart.py):
    # - Residential proxy for sitemaps (fast XML fetching)
    # - Web Scraper API for store pages (JS rendering for __NEXT_DATA__)
    # Note: Config below sets residential for sitemaps; scraper auto-creates
    # web_scraper_api session for store extraction
    proxy:
      mode: "residential"  # Used for sitemap fetching only
    output_fields:
      - store_id
      - name
      - store_type
      - street_address
      - city
      - state
      - zip
      - country
      - latitude
      - longitude
      - phone
      - has_curbside_pickup
      - has_instore_pickup
      - has_delivery
      - has_in_home_delivery
      - has_pharmacy
      - has_wireless_service
      - has_fuel_station
      - has_auto_care
      - is_glass_eligible
      - url
      - scraped_at

  bestbuy:
    name: "Best Buy"
    enabled: true
    base_url: "https://www.bestbuy.com"
    # Health check uses sitemap URL (no bot protection) instead of base_url (Akamai-protected)
    health_check_url: "https://stores.bestbuy.com/sitemap1.xml"
    sitemap_urls:
      - "https://stores.bestbuy.com/sitemap1.xml"
    discovery_method: "sitemap"

    # Performance settings (5x speedup with parallel extraction)
    parallel_workers: 5
    extraction_batch_size: 500
    checkpoint_interval: 25  # More frequent with parallel extraction
    url_cache_days: 7

    # Dual delay profiles for proxy vs direct mode
    delays:
      direct:
        min_delay: 2.0
        max_delay: 5.0
      proxied:
        min_delay: 0.2
        max_delay: 0.5

    # Disable pauses for proxy mode (handled by proxy rotation)
    pause_50_requests: 999999
    pause_200_requests: 999999
    pause_50_min: 0
    pause_50_max: 0
    pause_200_min: 0
    pause_200_max: 0

    # Proxy: Web Scraper API for Akamai bypass with JS rendering
    proxy:
      mode: "web_scraper_api"
      render_js: true

    output_fields:
      - store_id
      - name
      - status
      - store_type
      - display_name
      - street_address
      - city
      - state
      - zip
      - country
      - latitude
      - longitude
      - phone
      - services
      - service_codes
      - hours
      - has_pickup
      - curbside_enabled
      - url
      - scraped_at

  telus:
    name: "Telus"
    enabled: true
    base_url: "https://stores.telus.com"
    # Telus uses Uberall API - single call returns all stores (no sitemap)
    sitemap_urls: []
    discovery_method: "api"
    api_url: "https://uberall.com/api/storefinders/WvKTSwsliw6eKvVJKXUpQ3vggaSxc9/locations/all"

    # Dual delay profiles (minimal impact since it's a single API call)
    delays:
      direct:
        min_delay: 0.5
        max_delay: 1.0
      proxied:
        min_delay: 0.1
        max_delay: 0.3

    # No checkpointing needed - single fast API call
    checkpoint_interval: 999999

    # No pauses needed - single request
    pause_50_requests: 999999
    pause_200_requests: 999999
    pause_50_min: 0
    pause_50_max: 0
    pause_200_min: 0
    pause_200_max: 0

    # Residential proxy for reliability and speed
    proxy:
      mode: "residential"
      render_js: false

    output_fields:
      - store_id
      - telus_id
      - name
      - street_address
      - city
      - state
      - postal_code
      - country
      - latitude
      - longitude
      - phone
      - hours
      - url
      - scraped_at

  cricket:
    name: "Cricket Wireless"
    enabled: true
    base_url: "https://www.cricketwireless.com"
    # Cricket uses Yext API with geographic grid discovery
    sitemap_urls: []
    discovery_method: "api"
    api_url: "https://prod-cdn.us.yextapis.com/v2/accounts/me/search/query"

    # Grid-based geographic search configuration
    grid_spacing_miles: 50

    # Dual delay profiles (API is lightweight, can be aggressive with proxies)
    delays:
      direct:
        min_delay: 0.3
        max_delay: 0.5
      proxied:
        min_delay: 0.1
        max_delay: 0.2

    # Parallel workers for grid scanning (reduced for direct mode)
    parallel_workers: 5

    # No checkpointing needed - parallel API-based scraper
    checkpoint_interval: 999999

    # Disable long pauses (API is lightweight)
    pause_50_requests: 999999
    pause_200_requests: 999999
    pause_50_min: 0
    pause_50_max: 0
    pause_200_min: 0
    pause_200_max: 0

    # Default to direct mode (use --proxy residential for faster scraping)
    proxy:
      mode: "direct"
      render_js: false

    output_fields:
      - store_id
      - name
      - store_type
      - street_address
      - city
      - state
      - zip
      - country
      - latitude
      - longitude
      - phone
      - url
      - hours_monday
      - hours_tuesday
      - hours_wednesday
      - hours_thursday
      - hours_friday
      - hours_saturday
      - hours_sunday
      - closed
      - scraped_at


  bell:
    name: "Bell"
    enabled: true
    base_url: "https://storelocator.bell.ca"
    sitemap_urls:
      - "https://storelocator.bell.ca/sitemap.xml"
    discovery_method: "sitemap"

    # Conservative delays (robots.txt specifies Crawl-delay: 10)
    delays:
      direct:
        min_delay: 10.0
        max_delay: 12.0
      proxied:
        min_delay: 2.0
        max_delay: 4.0

    # Checkpoint interval for resume support
    checkpoint_interval: 25

    # Single worker due to crawl-delay requirement
    parallel_workers: 1

    # Disable long pauses (already respecting crawl-delay)
    pause_50_requests: 999999
    pause_200_requests: 999999
    pause_50_min: 0
    pause_50_max: 0
    pause_200_min: 0
    pause_200_max: 0

    # Direct mode - no aggressive bot protection observed
    proxy:
      mode: "direct"
      render_js: false

    output_fields:
      - store_id
      - name
      - street_address
      - city
      - state
      - postal_code
      - country
      - phone
      - hours
      - services
      - store_type
      - has_curbside
      - url
      - scraped_at

  costco:
    name: "Costco"
    enabled: true
    base_url: "https://www.costco.com"
    # Health check uses robots.txt (no bot protection) instead of base_url (Akamai-protected)
    health_check_url: "https://www.costco.com/robots.txt"
    # Costco uses Akamai bot protection - requires Web Scraper API with JS rendering
    sitemap_urls: []
    discovery_method: "page_scrape"
    locations_url: "https://www.costco.com/w/-/locations"

    # Dual delay profiles (more conservative due to bot protection)
    delays:
      direct:
        min_delay: 2.0
        max_delay: 4.0
      proxied:
        min_delay: 1.0
        max_delay: 2.0

    # Parallel workers (keep low due to bot protection)
    parallel_workers: 3

    # Checkpoint interval for resume support
    checkpoint_interval: 25

    # Disable long pauses when using proxy
    pause_50_requests: 999999
    pause_200_requests: 999999
    pause_50_min: 0
    pause_50_max: 0
    pause_200_min: 0
    pause_200_max: 0

    # Default to web_scraper_api due to Akamai protection
    proxy:
      mode: "web_scraper_api"
      render_js: true

    output_fields:
      - store_id
      - name
      - store_type
      - street_address
      - city
      - state
      - zip
      - country
      - latitude
      - longitude
      - phone
      - url
      - services
      - hours_weekday
      - hours_saturday
      - hours_sunday
      - scraped_at

  samsclub:
    name: "Sam's Club"
    enabled: true
    base_url: "https://www.samsclub.com"
    # Sam's Club uses Akamai bot protection - requires Web Scraper API with JS rendering
    # Discovery via sitemap (no protection), extraction via Web Scraper API
    sitemap_urls:
      - "https://www.samsclub.com/sitemap_locators.xml"
    discovery_method: "sitemap"

    # Dual delay profiles (Web Scraper API handles rate limiting)
    delays:
      direct:
        min_delay: 1.0
        max_delay: 2.0
      proxied:
        min_delay: 0.5
        max_delay: 1.0

    # Checkpoint interval for resume support
    checkpoint_interval: 50

    # Disable long pauses when using proxy
    pause_50_requests: 999999
    pause_200_requests: 999999
    pause_50_min: 0
    pause_50_max: 0
    pause_200_min: 0
    pause_200_max: 0

    # HYBRID PROXY MODE:
    # - Sitemap fetching uses direct mode (no bot protection)
    # - Club page extraction uses web_scraper_api (Akamai bypass with JS rendering)
    proxy:
      mode: "web_scraper_api"
      render_js: true

    output_fields:
      - store_id
      - name
      - street_address
      - city
      - state
      - zip
      - county
      - country
      - latitude
      - longitude
      - phone
      - url
      - time_zone
      - services
      - has_pharmacy
      - has_optical
      - has_hearing_aid
      - has_wireless
      - has_cafe
      - has_bakery
      - has_gas
      - has_liquor
      - has_tires_batteries
      - is_curbside
      - is_scan_and_go
      - is_same_day_pickup
      - hours_mon_fri
      - hours_saturday
      - hours_sunday
      - plus_hours_mon_fri
      - plus_hours_saturday
      - plus_hours_sunday
      - scraped_at
